### YamlMime:UniversalReference
ms.openlocfilehash: f7bb0a77329788feb31835819b61ccba9c59535e
ms.sourcegitcommit: efa2d98deffe8a0d41a8d63f9f07aa720862e6ab
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 12/13/2018
ms.locfileid: "52026125"
items:
- uid: azure-cognitiveservices-computervision.ComputerVisionClient
  name: ComputerVisionClient
  fullName: ComputerVisionClient
  children:
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.constructor
  - azure-cognitiveservices-computervision.ComputerVisionClient.credentials
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
  - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.listModels
  - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
  langs:
  - typeScript
  type: class
  summary: ''
  extends:
    name: ServiceClient
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
  name: analyzeImage(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image.  Au sein de votre demande, il existe un paramètre facultatif pour vous permettre de choisir les fonctionnalités à retourner.  Par défaut, les catégories de l’image sont retournés dans la réponse.'
  syntax:
    content: 'function analyzeImage(url: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
  name: analyzeImage(string, Object, ServiceCallback<ImageAnalysis>)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image.  Au sein de votre demande, il existe un paramètre facultatif pour vous permettre de choisir les fonctionnalités à retourner.  Par défaut, les catégories de l’image sont retournés dans la réponse.'
  syntax:
    content: 'function analyzeImage(url: string, options: Object, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
  name: analyzeImage(string, ServiceCallback<ImageAnalysis>)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image.  Au sein de votre demande, il existe un paramètre facultatif pour vous permettre de choisir les fonctionnalités à retourner.  Par défaut, les catégories de l’image sont retournés dans la réponse.'
  syntax:
    content: 'function analyzeImage(url: string, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
  name: analyzeImageByDomain(string, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, options?: Object)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Contenu spécifique à un domaine à reconnaître.
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
  name: analyzeImageByDomain(string, string, Object, ServiceCallback<DomainModelResults>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, options: Object, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
  name: analyzeImageByDomain(string, string, ServiceCallback<DomainModelResults>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
  name: analyzeImageByDomainInStream(string, stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options?: Object)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Contenu spécifique à un domaine à reconnaître.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
  name: analyzeImageByDomainInStream(string, stream.Readable, Object, ServiceCallback<DomainModelResults>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options: Object, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
  name: analyzeImageByDomainInStream(string, stream.Readable, ServiceCallback<DomainModelResults>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
  name: analyzeImageByDomainInStreamWithHttpOperationResponse(string, stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomainInStreamWithHttpOperationResponse(model: string, image: stream.Readable, options?: Object)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Contenu spécifique à un domaine à reconnaître.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
  name: analyzeImageByDomainWithHttpOperationResponse(string, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomainWithHttpOperationResponse(model: string, url: string, options?: Object)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Contenu spécifique à un domaine à reconnaître.
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
  name: analyzeImageInStream(stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
  name: analyzeImageInStream(stream.Readable, Object, ServiceCallback<ImageAnalysis>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
  name: analyzeImageInStream(stream.Readable, ServiceCallback<ImageAnalysis>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
  name: analyzeImageInStreamWithHttpOperationResponse(stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image.
  syntax:
    content: 'function analyzeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
  name: analyzeImageWithHttpOperationResponse(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image.  Au sein de votre demande, il existe un paramètre facultatif pour vous permettre de choisir les fonctionnalités à retourner.  Par défaut, les catégories de l’image sont retournés dans la réponse.'
  syntax:
    content: 'function analyzeImageWithHttpOperationResponse(url: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.constructor
  name: ComputerVisionClient(ServiceClientCredentials, string, ServiceClientOptions)
  children: []
  type: constructor
  langs:
  - typeScript
  summary: ''
  syntax:
    content: 'new ComputerVisionClient(credentials: ServiceClientCredentials, endpoint: string, options?: ServiceClientOptions)'
    parameters:
    - id: credentials
      type:
      - ServiceClientCredentials
      description: >
        Informations d’identification d’abonnement qui identifient l’abonnement du client.
    - id: endpoint
      type:
      - string
      description: >
        Points de terminaison pris en charge Cognitive Services
    - id: options
      type:
      - ServiceClientOptions
      description: ''
      optional: true
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.credentials
  name: credentials
  fullName: credentials
  children: []
  langs:
  - typeScript
  type: property
  summary: ''
  syntax:
    content: 'credentials: ServiceClientCredentials'
    return:
      type:
      - ServiceClientCredentials
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
  name: describeImage(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImage(url: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
  name: describeImage(string, Object, ServiceCallback<ImageDescription>)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImage(url: string, options: Object, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
  name: describeImage(string, ServiceCallback<ImageDescription>)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImage(url: string, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
  name: describeImageInStream(stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
  name: describeImageInStream(stream.Readable, Object, ServiceCallback<ImageDescription>)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
  name: describeImageInStream(stream.Readable, ServiceCallback<ImageDescription>)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
  name: describeImageInStreamWithHttpOperationResponse(stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
  name: describeImageWithHttpOperationResponse(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImageWithHttpOperationResponse(url: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
  name: endpoint
  fullName: endpoint
  children: []
  langs:
  - typeScript
  type: property
  summary: ''
  syntax:
    content: 'endpoint: string'
    return:
      type:
      - string
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
  name: generateThumbnail(number, number, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature au format binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, options?: Object)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Largeur de la miniature. Il doit comprendre entre 1 et 1 024.

        Minimum recommandé de 50.
    - id: height
      type:
      - number
      description: >
        Hauteur de la miniature. Il doit être comprise entre 1 et

        1024. Minimum recommandé de 50.
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
  name: generateThumbnail(number, number, string, Object, ServiceCallback<stream.Readable>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature au format binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, options: Object, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
  name: generateThumbnail(number, number, string, ServiceCallback<stream.Readable>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature au format binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
  name: generateThumbnailInStream(number, number, stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature au format binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options?: Object)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Largeur de la miniature. Il doit comprendre entre 1 et 1 024.

        Minimum recommandé de 50.
    - id: height
      type:
      - number
      description: >
        Hauteur de la miniature. Il doit être comprise entre 1 et

        1024. Minimum recommandé de 50.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
  name: generateThumbnailInStream(number, number, stream.Readable, Object, ServiceCallback<stream.Readable>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature au format binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options: Object, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
  name: generateThumbnailInStream(number, number, stream.Readable, ServiceCallback<stream.Readable>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature au format binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
  name: generateThumbnailInStreamWithHttpOperationResponse(number, number, stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature au format binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnailInStreamWithHttpOperationResponse(width: number, height: number, image: stream.Readable, options?: Object)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Largeur de la miniature. Il doit comprendre entre 1 et 1 024.

        Minimum recommandé de 50.
    - id: height
      type:
      - number
      description: >
        Hauteur de la miniature. Il doit être comprise entre 1 et

        1024. Minimum recommandé de 50.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<stream.Readable>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
  name: generateThumbnailWithHttpOperationResponse(number, number, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature au format binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnailWithHttpOperationResponse(width: number, height: number, url: string, options?: Object)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Largeur de la miniature. Il doit comprendre entre 1 et 1 024.

        Minimum recommandé de 50.
    - id: height
      type:
      - number
      description: >
        Hauteur de la miniature. Il doit être comprise entre 1 et

        1024. Minimum recommandé de 50.
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<stream.Readable>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
  name: getTextOperationResult(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette interface est utilisée pour obtenir le résultat d’opération de texte. L’URL à cette interface doit être extrait du champ « Operation-Location » retourné à partir de l’interface de reconnaître le texte.
  syntax:
    content: 'function getTextOperationResult(operationId: string, options?: Object)'
    parameters:
    - id: operationId
      type:
      - string
      description: >
        ID de l’opération de texte renvoyée dans la réponse de la « reconnaître le texte'
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
  name: getTextOperationResult(string, Object, ServiceCallback<TextOperationResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette interface est utilisée pour obtenir le résultat d’opération de texte. L’URL à cette interface doit être extrait du champ « Operation-Location » retourné à partir de l’interface de reconnaître le texte.
  syntax:
    content: 'function getTextOperationResult(operationId: string, options: Object, callback: ServiceCallback<TextOperationResult>)'
    parameters:
    - id: operationId
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
  name: getTextOperationResult(string, ServiceCallback<TextOperationResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette interface est utilisée pour obtenir le résultat d’opération de texte. L’URL à cette interface doit être extrait du champ « Operation-Location » retourné à partir de l’interface de reconnaître le texte.
  syntax:
    content: 'function getTextOperationResult(operationId: string, callback: ServiceCallback<TextOperationResult>)'
    parameters:
    - id: operationId
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
  name: getTextOperationResultWithHttpOperationResponse(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette interface est utilisée pour obtenir le résultat d’opération de texte. L’URL à cette interface doit être extrait du champ « Operation-Location » retourné à partir de l’interface de reconnaître le texte.
  syntax:
    content: 'function getTextOperationResultWithHttpOperationResponse(operationId: string, options?: Object)'
    parameters:
    - id: operationId
      type:
      - string
      description: >
        ID de l’opération de texte renvoyée dans la réponse de la « reconnaître le texte'
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels
  name: listModels(Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération renvoie la liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur.  Actuellement, l’API prend uniquement en charge un modèle spécifique à un domaine : un module de reconnaissance de célébrités. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function listModels(options?: Object)'
    parameters:
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
  name: listModels(Object, ServiceCallback<ListModelsResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération renvoie la liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur.  Actuellement, l’API prend uniquement en charge un modèle spécifique à un domaine : un module de reconnaissance de célébrités. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function listModels(options: Object, callback: ServiceCallback<ListModelsResult>)'
    parameters:
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
  name: listModels(ServiceCallback<ListModelsResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération renvoie la liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur.  Actuellement, l’API prend uniquement en charge un modèle spécifique à un domaine : un module de reconnaissance de célébrités. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function listModels(callback: ServiceCallback<ListModelsResult>)'
    parameters:
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
  name: listModelsWithHttpOperationResponse(Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération renvoie la liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur.  Actuellement, l’API prend uniquement en charge un modèle spécifique à un domaine : un module de reconnaissance de célébrités. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function listModelsWithHttpOperationResponse(options?: Object)'
    parameters:
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
  name: recognizePrintedText(boolean, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options?: Object)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Détecter si l’orientation du texte dans l’image. Avec detectOrientation = true, la reconnaissance optique de caractères service tente de détecter l’orientation de l’image et corrigez-le avant tout traitement supplémentaire (par exemple, s’il s’agit envers).
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
  name: recognizePrintedText(boolean, string, Object, ServiceCallback<OcrResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options: Object, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
  name: recognizePrintedText(boolean, string, ServiceCallback<OcrResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
  name: recognizePrintedTextInStream(boolean, stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options?: Object)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Détecter si l’orientation du texte dans l’image. Avec detectOrientation = true, la reconnaissance optique de caractères service tente de détecter l’orientation de l’image et corrigez-le avant tout traitement supplémentaire (par exemple, s’il s’agit envers).
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
  name: recognizePrintedTextInStream(boolean, stream.Readable, Object, ServiceCallback<OcrResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options: Object, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
  name: recognizePrintedTextInStream(boolean, stream.Readable, ServiceCallback<OcrResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
  name: recognizePrintedTextInStreamWithHttpOperationResponse(boolean, stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedTextInStreamWithHttpOperationResponse(detectOrientation: boolean, image: stream.Readable, options?: Object)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Détecter si l’orientation du texte dans l’image. Avec detectOrientation = true, la reconnaissance optique de caractères service tente de détecter l’orientation de l’image et corrigez-le avant tout traitement supplémentaire (par exemple, s’il s’agit envers).
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
  name: recognizePrintedTextWithHttpOperationResponse(boolean, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedTextWithHttpOperationResponse(detectOrientation: boolean, url: string, options?: Object)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Détecter si l’orientation du texte dans l’image. Avec detectOrientation = true, la reconnaissance optique de caractères service tente de détecter l’orientation de l’image et corrigez-le avant tout traitement supplémentaire (par exemple, s’il s’agit envers).
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
  name: recognizeText(string, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Operation-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte reconnaître.
  syntax:
    content: 'function recognizeText(url: string, mode: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: mode
      type:
      - string
      description: >
        Type de texte à reconnaître. Les valeurs possibles incluent : 'Main', 'imprimé'
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
  name: recognizeText(string, string, Object, ServiceCallback<void>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Operation-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte reconnaître.
  syntax:
    content: 'function recognizeText(url: string, mode: string, options: Object, callback: ServiceCallback<void>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: mode
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
  name: recognizeText(string, string, ServiceCallback<void>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Operation-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte reconnaître.
  syntax:
    content: 'function recognizeText(url: string, mode: string, callback: ServiceCallback<void>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: mode
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
  name: recognizeTextInStream(stream.Readable, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Operation-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte reconnaître.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, mode: string, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: mode
      type:
      - string
      description: >
        Type de texte à reconnaître. Les valeurs possibles incluent : 'Main', 'imprimé'
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
  name: recognizeTextInStream(stream.Readable, string, Object, ServiceCallback<void>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Operation-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte reconnaître.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, mode: string, options: Object, callback: ServiceCallback<void>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: mode
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
  name: recognizeTextInStream(stream.Readable, string, ServiceCallback<void>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Operation-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte reconnaître.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, mode: string, callback: ServiceCallback<void>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: mode
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
  name: recognizeTextInStreamWithHttpOperationResponse(stream.Readable, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Operation-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte reconnaître.
  syntax:
    content: 'function recognizeTextInStreamWithHttpOperationResponse(image: stream.Readable, mode: string, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: mode
      type:
      - string
      description: >
        Type de texte à reconnaître. Les valeurs possibles incluent : 'Main', 'imprimé'
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<void>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
  name: recognizeTextWithHttpOperationResponse(string, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Operation-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte reconnaître.
  syntax:
    content: 'function recognizeTextWithHttpOperationResponse(url: string, mode: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: mode
      type:
      - string
      description: >
        Type de texte à reconnaître. Les valeurs possibles incluent : 'Main', 'imprimé'
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<void>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
  name: tagImage(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur instrument de musique. Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImage(url: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
  name: tagImage(string, Object, ServiceCallback<TagResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur instrument de musique. Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImage(url: string, options: Object, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
  name: tagImage(string, ServiceCallback<TagResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur instrument de musique. Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImage(url: string, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
  name: tagImageInStream(stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur instrument de musique. Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
  name: tagImageInStream(stream.Readable, Object, ServiceCallback<TagResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur instrument de musique. Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
  name: tagImageInStream(stream.Readable, ServiceCallback<TagResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur instrument de musique. Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
  name: tagImageInStreamWithHttpOperationResponse(stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur instrument de musique. Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
  name: tagImageWithHttpOperationResponse(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur instrument de musique. Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImageWithHttpOperationResponse(url: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        URL accessible publiquement d’une image
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  package: azure-cognitiveservices-computervision
references:
- uid: Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  name: ImageAnalysis>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
  name: ImageAnalysis>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>'
    fullName: '>'
- uid: Promise<azure-cognitiveservices-computervision.DomainModelResults>
  name: DomainModelResults>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
  name: DomainModelResults>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  name: DomainModelResults>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>>'
    fullName: '>>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  name: ImageAnalysis>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.ImageDescription>
  name: ImageDescription>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
  name: ImageDescription>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  name: ImageDescription>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.TextOperationResult>
  name: TextOperationResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
  name: TextOperationResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
  name: TextOperationResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.ListModelsResult>
  name: ListModelsResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
  name: ListModelsResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
  name: ListModelsResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.OcrResult>
  name: OcrResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
  name: OcrResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  name: OcrResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.TagResult>
  name: TagResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.TagResult>
  name: TagResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  name: TagResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>>'
    fullName: '>>'
