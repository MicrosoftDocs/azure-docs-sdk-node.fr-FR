### YamlMime:UniversalReference
ms.openlocfilehash: 496552af79989c144ce96db561de8b0882be0c21
ms.sourcegitcommit: 506ba44827323385ad0fd81cd14f70c52fd0371e
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 08/22/2018
ms.locfileid: "40465612"
items:
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient
  name: ComputerVisionAPIClient
  fullName: ComputerVisionAPIClient
  children:
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.azureRegion
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.constructor
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.credentials
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResultWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModelsWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageWithHttpOperationResponse
  langs:
  - typeScript
  type: class
  summary: ''
  extends:
    name: ServiceClient
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage
  name: analyzeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image.  Au sein de votre demande, il existe un paramètre facultatif pour vous permettre de choisir les fonctionnalités à retourner.  Par défaut, les catégories de l’image sont retournés dans la réponse.'
  syntax:
    content: 'function analyzeImage(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_2
  name: analyzeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image.  Au sein de votre demande, il existe un paramètre facultatif pour vous permettre de choisir les fonctionnalités à retourner.  Par défaut, les catégories de l’image sont retournés dans la réponse.'
  syntax:
    content: 'function analyzeImage(url: string, options: function, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_1
  name: analyzeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image.  Au sein de votre demande, il existe un paramètre facultatif pour vous permettre de choisir les fonctionnalités à retourner.  Par défaut, les catégories de l’image sont retournés dans la réponse.'
  syntax:
    content: 'function analyzeImage(url: string, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain
  name: analyzeImageByDomain
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, options?: function)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Contenu spécifique à un domaine à reconnaître. Les valeurs possibles sont : « Célébrités », « Points de repère »
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_1
  name: analyzeImageByDomain
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_2
  name: analyzeImageByDomain
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, options: function, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream
  name: analyzeImageByDomainInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options?: function)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Contenu spécifique à un domaine à reconnaître.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_1
  name: analyzeImageByDomainInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_2
  name: analyzeImageByDomainInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options: function, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStreamWithHttpOperationResponse
  name: analyzeImageByDomainInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomainInStreamWithHttpOperationResponse(model: string, image: stream.Readable, options?: function)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Contenu spécifique à un domaine à reconnaître.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainWithHttpOperationResponse
  name: analyzeImageByDomainWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération reconnaît le contenu au sein d’une image en appliquant un modèle spécifique à un domaine.  La liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur peut être récupérée à l’aide de la demande d’obtention de /models.  Actuellement, l’API fournit uniquement un modèle spécifique à un domaine unique : célébrités. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.

    Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.
  syntax:
    content: 'function analyzeImageByDomainWithHttpOperationResponse(model: string, url: string, options?: function)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Contenu spécifique à un domaine à reconnaître. Les valeurs possibles sont : « Célébrités », « Points de repère »
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream
  name: analyzeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_1
  name: analyzeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_2
  name: analyzeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, options: function, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStreamWithHttpOperationResponse
  name: analyzeImageInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image.
  syntax:
    content: 'function analyzeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageWithHttpOperationResponse
  name: analyzeImageWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération extrait un ensemble complet de fonctionnalités visuelles en fonction du contenu de l’image. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image.  Au sein de votre demande, il existe un paramètre facultatif pour vous permettre de choisir les fonctionnalités à retourner.  Par défaut, les catégories de l’image sont retournés dans la réponse.'
  syntax:
    content: 'function analyzeImageWithHttpOperationResponse(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.azureRegion
  name: azureRegion
  fullName: azureRegion
  children: []
  langs:
  - typeScript
  type: property
  summary: ''
  syntax:
    content: 'azureRegion: string'
    return:
      type:
      - string
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.constructor
  name: ComputerVisionAPIClient
  children: []
  type: constructor
  langs:
  - typeScript
  summary: ''
  syntax:
    content: 'new ComputerVisionAPIClient(credentials: ServiceClientCredentials, azureRegion: string, options?: ServiceClientOptions)'
    parameters:
    - id: credentials
      type:
      - ServiceClientCredentials
      description: >
        Informations d’identification d’abonnement qui identifient l’abonnement du client.
    - id: azureRegion
      type:
      - string
      description: >
        Régions Azure prises en charge pour les points de terminaison Cognitive Services. Les valeurs possibles sont : 'westus', 'westeurope', 'southeastasia', 'eastus2', 'westcentralus', 'westus2', 'eastus', 'southcentralus', 'northeurope', 'eastasia', 'australiaeast', 'brazilsouth'
    - id: options
      type:
      - ServiceClientOptions
      description: ''
      optional: true
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.credentials
  name: credentials
  fullName: credentials
  children: []
  langs:
  - typeScript
  type: property
  summary: ''
  syntax:
    content: 'credentials: ServiceClientCredentials'
    return:
      type:
      - ServiceClientCredentials
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_1
  name: describeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImage(url: string, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage
  name: describeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImage(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_2
  name: describeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImage(url: string, options: function, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream
  name: describeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_1
  name: describeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_2
  name: describeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, options: function, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStreamWithHttpOperationResponse
  name: describeImageInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageWithHttpOperationResponse
  name: describeImageWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération génère une description d’une image dans un langage lisible humain avec des phrases complètes.  La description est basée sur une collection de balises de contenu, qui sont également retournées par l’opération. Plus d’une description peut être générée pour chaque image.  Descriptions sont triées par leur score de confiance. Toutes les descriptions sont en anglais. Deux méthodes d’entrée sont pris en charge : chargement d’une image (1) ou (2) en spécifiant une URL d’image. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function describeImageWithHttpOperationResponse(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_1
  name: generateThumbnail
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_2
  name: generateThumbnail
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, options: function, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail
  name: generateThumbnail
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, options?: function)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Largeur de la miniature. Il doit comprendre entre 1 et 1 024.

        Minimum recommandé de 50.
    - id: height
      type:
      - number
      description: >
        Hauteur de la miniature. Il doit être comprise entre 1 et

        1024. Minimum recommandé de 50.
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream
  name: generateThumbnailInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options?: function)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Largeur de la miniature. Il doit comprendre entre 1 et 1 024.

        Minimum recommandé de 50.
    - id: height
      type:
      - number
      description: >
        Hauteur de la miniature. Il doit être comprise entre 1 et

        1024. Minimum recommandé de 50.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_1
  name: generateThumbnailInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_2
  name: generateThumbnailInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options: function, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStreamWithHttpOperationResponse
  name: generateThumbnailInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnailInStreamWithHttpOperationResponse(width: number, height: number, image: stream.Readable, options?: function)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Largeur de la miniature. Il doit comprendre entre 1 et 1 024.

        Minimum recommandé de 50.
    - id: height
      type:
      - number
      description: >
        Hauteur de la miniature. Il doit être comprise entre 1 et

        1024. Minimum recommandé de 50.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<stream.Readable>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailWithHttpOperationResponse
  name: generateThumbnailWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Cette opération génère une image miniature avec la hauteur et la largeur spécifiée par l’utilisateur. Par défaut, le service analyse l’image, identifie la région d’intérêt (ROI) et génère des coordonnées de rognage intelligentes basées sur le retour sur investissement.

    Rognage intelligent aide lorsque vous spécifiez un rapport hauteur / largeur différent de celui de l’image d’entrée. Une réponse correcte contient l’image miniature binaire. Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à déterminer la cause du problème.
  syntax:
    content: 'function generateThumbnailWithHttpOperationResponse(width: number, height: number, url: string, options?: function)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Largeur de la miniature. Il doit comprendre entre 1 et 1 024.

        Minimum recommandé de 50.
    - id: height
      type:
      - number
      description: >
        Hauteur de la miniature. Il doit être comprise entre 1 et

        1024. Minimum recommandé de 50.
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<stream.Readable>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult
  name: getTextOperationResult
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette interface est utilisée pour obtenir le résultat d’opération de texte. L’URL à cette interface doit être extrait du champ « Operation-Location » retourné à partir de l’interface de reconnaître le texte.
  syntax:
    content: 'function getTextOperationResult(operationId: string, options?: function)'
    parameters:
    - id: operationId
      type:
      - string
      description: >
        ID de l’opération de texte renvoyée dans la réponse du « Reconnaître manuscrites texte »
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_2
  name: getTextOperationResult
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette interface est utilisée pour obtenir le résultat d’opération de texte. L’URL à cette interface doit être extrait du champ « Operation-Location » retourné à partir de l’interface de reconnaître le texte.
  syntax:
    content: 'function getTextOperationResult(operationId: string, options: function, callback: ServiceCallback<TextOperationResult>)'
    parameters:
    - id: operationId
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_1
  name: getTextOperationResult
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette interface est utilisée pour obtenir le résultat d’opération de texte. L’URL à cette interface doit être extrait du champ « Operation-Location » retourné à partir de l’interface de reconnaître le texte.
  syntax:
    content: 'function getTextOperationResult(operationId: string, callback: ServiceCallback<TextOperationResult>)'
    parameters:
    - id: operationId
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResultWithHttpOperationResponse
  name: getTextOperationResultWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette interface est utilisée pour obtenir le résultat d’opération de texte. L’URL à cette interface doit être extrait du champ « Operation-Location » retourné à partir de l’interface de reconnaître le texte.
  syntax:
    content: 'function getTextOperationResultWithHttpOperationResponse(operationId: string, options?: function)'
    parameters:
    - id: operationId
      type:
      - string
      description: >
        ID de l’opération de texte renvoyée dans la réponse du « Reconnaître manuscrites texte »
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels
  name: listModels
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération renvoie la liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur.  Actuellement, l’API prend uniquement en charge un modèle spécifique à un domaine : un module de reconnaissance de célébrités. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function listModels(options?: function)'
    parameters:
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_2
  name: listModels
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération renvoie la liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur.  Actuellement, l’API prend uniquement en charge un modèle spécifique à un domaine : un module de reconnaissance de célébrités. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function listModels(options: function, callback: ServiceCallback<ListModelsResult>)'
    parameters:
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_1
  name: listModels
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération renvoie la liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur.  Actuellement, l’API prend uniquement en charge un modèle spécifique à un domaine : un module de reconnaissance de célébrités. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function listModels(callback: ServiceCallback<ListModelsResult>)'
    parameters:
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModelsWithHttpOperationResponse
  name: listModelsWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: 'Cette opération renvoie la liste des modèles spécifiques à un domaine qui sont pris en charge par l’API vision par ordinateur.  Actuellement, l’API prend uniquement en charge un modèle spécifique à un domaine : un module de reconnaissance de célébrités. Une réponse correcte s’affichera dans JSON.  Si la demande a échoué, la réponse contient un code d’erreur et un message pour aider à comprendre la cause du problème.'
  syntax:
    content: 'function listModelsWithHttpOperationResponse(options?: function)'
    parameters:
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_1
  name: recognizePrintedText
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText
  name: recognizePrintedText
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options?: function)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Détecter si l’orientation du texte dans l’image. Avec detectOrientation = true, la reconnaissance optique de caractères service tente de détecter l’orientation de l’image et corrigez-le avant tout traitement supplémentaire (par exemple, s’il s’agit envers).
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_2
  name: recognizePrintedText
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options: function, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream
  name: recognizePrintedTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options?: function)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Détecter si l’orientation du texte dans l’image. Avec detectOrientation = true, la reconnaissance optique de caractères service tente de détecter l’orientation de l’image et corrigez-le avant tout traitement supplémentaire (par exemple, s’il s’agit envers).
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_1
  name: recognizePrintedTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_2
  name: recognizePrintedTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options: function, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStreamWithHttpOperationResponse
  name: recognizePrintedTextInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedTextInStreamWithHttpOperationResponse(detectOrientation: boolean, image: stream.Readable, options?: function)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Détecter si l’orientation du texte dans l’image. Avec detectOrientation = true, la reconnaissance optique de caractères service tente de détecter l’orientation de l’image et corrigez-le avant tout traitement supplémentaire (par exemple, s’il s’agit envers).
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextWithHttpOperationResponse
  name: recognizePrintedTextWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Reconnaissance optique de caractères (OCR) détecte le texte imprimé dans une image et extrait les caractères reconnus dans un flux de caractères exploitable.

    En cas de réussite, les résultats de la reconnaissance optique de caractères seront affichera. En cas d’échec, le code d’erreur avec un message d’erreur s’affichera. Le code d’erreur peut être une des InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage ou InternalServerError.
  syntax:
    content: 'function recognizePrintedTextWithHttpOperationResponse(detectOrientation: boolean, url: string, options?: function)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Détecter si l’orientation du texte dans l’image. Avec detectOrientation = true, la reconnaissance optique de caractères service tente de détecter l’orientation de l’image et corrigez-le avant tout traitement supplémentaire (par exemple, s’il s’agit envers).
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText
  name: recognizeText
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Opération-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte écrit à la main.
  syntax:
    content: 'function recognizeText(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_2
  name: recognizeText
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Opération-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte écrit à la main.
  syntax:
    content: 'function recognizeText(url: string, options: function, callback: ServiceCallback<void>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_1
  name: recognizeText
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Opération-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte écrit à la main.
  syntax:
    content: 'function recognizeText(url: string, callback: ServiceCallback<void>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream
  name: recognizeTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Opération-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte écrit à la main.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_1
  name: recognizeTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Opération-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte écrit à la main.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, callback: ServiceCallback<void>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_2
  name: recognizeTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Opération-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte écrit à la main.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, options: function, callback: ServiceCallback<void>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStreamWithHttpOperationResponse
  name: recognizeTextInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Opération-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte écrit à la main.
  syntax:
    content: 'function recognizeTextInStreamWithHttpOperationResponse(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<void>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextWithHttpOperationResponse
  name: recognizeTextWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Reconnaître l’opération de texte. Lorsque vous utilisez l’interface de reconnaître le texte, la réponse contient un champ appelé « Operation-Location ». Le champ « Opération-Location » contient l’URL que vous devez utiliser pour votre opération obtenir le résultat d’opération texte écrit à la main.
  syntax:
    content: 'function recognizeTextWithHttpOperationResponse(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<void>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage
  name: tagImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur « instrument de musique ». Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImage(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_1
  name: tagImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur « instrument de musique ». Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImage(url: string, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_2
  name: tagImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur « instrument de musique ». Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImage(url: string, options: function, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream
  name: tagImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur « instrument de musique ». Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_1
  name: tagImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur « instrument de musique ». Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_2
  name: tagImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur « instrument de musique ». Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, options: function, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStreamWithHttpOperationResponse
  name: tagImageInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur « instrument de musique ». Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flux d’image.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageWithHttpOperationResponse
  name: tagImageWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Cette opération génère une liste de mots ou de balises, qui sont pertinents pour le contenu de l’image fournie. L’API vision par ordinateur peut retourner balises basées sur les objets, vivant êtres humains, vivants ou actions trouvées dans les images. Contrairement aux catégories, les balises ne sont pas organisées selon un système de classification hiérarchique, mais correspondent au contenu de l’image. Les balises peuvent contenir des conseils pour éviter toute ambiguïté ou fournir un contexte, par exemple le cello « tag » peut être accompagné par l’indicateur « instrument de musique ». Toutes les balises sont en anglais.
  syntax:
    content: 'function tagImageWithHttpOperationResponse(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  package: azure-cognitiveservices-computervision
references:
- uid: Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>'
    fullName: '>'
- uid: Promise<azure-cognitiveservices-computervision.DomainModelResults>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>>'
    fullName: '>>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.ImageDescription>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.TextOperationResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.ListModelsResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.OcrResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.TagResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.TagResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>>'
    fullName: '>>'
