### YamlMime:UniversalReference
ms.openlocfilehash: f4ecb7ab933b794f77479de848453841eb3da99c
ms.sourcegitcommit: ce76ec3eda83746ef9a765165173b5c00b5b7df6
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 12/20/2018
ms.locfileid: "53664083"
items:
- uid: azure-arm-mediaservices.OutputFile
  name: OutputFile
  fullName: OutputFile
  children:
  - azure-arm-mediaservices.OutputFile.labels
  langs:
  - typeScript
  type: interface
  summary: <span data-ttu-id="87144-101">Représente un fichier de sortie produit.</span><span class="sxs-lookup"><span data-stu-id="87144-101">Represents an output file produced.</span></span>
  package: azure-arm-mediaservices
- uid: azure-arm-mediaservices.OutputFile.labels
  name: labels
  fullName: labels
  children: []
  langs:
  - typeScript
  type: property
  summary: <span data-ttu-id="87144-102">La liste des étiquettes qui décrivent comment l’encodeur doit multiplexer audio et vidéo dans un fichier de sortie.</span><span class="sxs-lookup"><span data-stu-id="87144-102">The list of labels that describe how the encoder should multiplex video and audio into an output file.</span></span> <span data-ttu-id="87144-103">Par exemple, si l’encodeur génère deux couches vidéo avec étiquettes v1 et v2 et une couche audio avec étiquette a1, un tableau comme « [v1, a1] » indique l’encodeur afin de produire un fichier de sortie avec la piste vidéo représentée par v1 et la piste audio représenté par a1.</span><span class="sxs-lookup"><span data-stu-id="87144-103">For example, if the encoder is producing two video layers with labels v1 and v2, and one audio layer with label a1, then an array like '[v1, a1]' tells the encoder to produce an output file with the video track represented by v1 and the audio track represented by a1.</span></span>
  optional: true
  syntax:
    content: 'labels?: string[]'
    return:
      type:
      - string[]
  package: azure-arm-mediaservices
